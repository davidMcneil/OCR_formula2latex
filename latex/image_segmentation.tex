\subsection{Image Segmentation}
Our entire methodology relies on successfully taking a raw image and converting it to a number of consistently sized binary images. Each of these images can be thought of as a tile containing one mathematical symbol found in the original image. This process of segmentation can be divided into two steps: conversion to binary, and separation of unique symbols.

Converting an image to black and white or binary is essential to accurately extracting individual symbols and providing consistent input for classification. Because of this, we developed a robust three step process for converting a gray image, with dark writing on a light background, to binary. We will outline each of these steps by looking at converting a sample image (Fig. \ref{IS_original}) to binary.

\addImage{images/IS_original.png}{Original Image}{IS_original}{.25}

Fig. \ref{IS_original} presents many challenges for conversion to binary. It was clearly taken with a flash which results in a bright region in the middle of the image as well as creating a gradient to extremely dark regions in the corners. 

\subsubsection{Applying an Intelligent Threshold}
We begin our approach by applying a dynamically calculated threshold to the original image. Pixels on either side of this threshold are cast to either black or white. The threshold is calculated using Matlab's built in \mcode{graythresh(BW)} function. \mcode{graythresh} uses Otsu's method to minimizes variance of the black and white pixel classes.

\addImage{images/IS_intellegent.png}{Intellegent Threshold}{IS_thresh}{.25}

The resulting image (Fig. \ref{IS_thresh}) clearly produces poor results. The entire dark boarder is misclassified. This demonstrates that using a threshold method alone is not sufficient to properly convert the image.

\subsubsection{K-means Clustering}
The next step is to use unsupervised machine learning to determine the breakpoints of the two classes. This is done using the K-means algorithm in Equation \ref{kmeans}.

\eq{minD = \sum\limits_{k=1}^K\sum\limits_{x_i\in C_k} ||x_i-m_k||^2}{kmeans}

$K$ is the number of clusters. In our case $K=2$ one cluster for both white and black pixels. Each $x$ is an individual pixel. $C_k$ is the set of pixels in cluster $k$ with $k$ having a mean of $m_k$.

\addImage{images/IS_kmeans.png}{K-means Classification}{IS_kmeans}{.25}

For this particular image K-means produced slightly better results than the threshold method (Fig. \ref{IS_kmeans} compared to Fig. \ref{IS_thresh}). However, we still misclassified a large number of exterior pixels. 

Our first two methods of converting to binary have relied entirely on color. The problem with this method is that the dark boarder pixels have a very similar color to that of the written symbols. Our next method will look at changes in color in order to improve classification of symbols.

\subsubsection{Edge Classification}
\addImage{images/IS_edges.png}{Edges using sobel filter}{IS_edges}{.25}

Fig. \ref{IS_edges} shows the results of running a sobel filter over the original image. The filter is able to perfectly distinguish the large changes in color from the whiteboard to the written symbols while ignoring the slow transition to darker color in the corners. 

How can we use these edges to recreate the original symbols? A very natural thought is to simply dilate the edges until they become connected. The question now becomes how much to dilate the image.

\addImage{images/IS_dist.png}{Distance to Edge Pixels}{IS_dist}{.25}

Fig. \ref{IS_dist} illustrates the distance of every pixel to the nearest edge pixel with white being furthest away and black actually being an edge pixel. We can then use this distance matrix to calculate the average linewidth of the symbols. This is done by extracting the local maximum from the distance matrix. 

\addImage{images/IS_max.png}{Local Maximum of Distance Matrix}{IS_max}{.25}

These local maximum represent approximately half of the line width. This is because these maximums occur when the distance matrix values transition from being closer to the exterior edge to the interior edge. We can then use the average of these local maximum to dilate the edge image.  

\addImage{images/IS_dial.png}{Dilated Edge Image}{IS_dial}{.25}

The results of the edge classification seen in Fig. \ref{IS_dial} clearly outperform either of the color based classification methods. However, the symbols lose some of their sharpness and become rounded due to the dilation. We can regain these features by using the results of converting to binary using the threshold or K-means algorithm.

We combine our results of the three methods by simply performing a logical ``and" on the three resultant images. Simply ``anding" the images together works because all three of the methods have a very high false positive rate and a very low false negative rate meaning they rarely do not classify the pixels that represent the written symbol correctly. The problem is they tend to over classify background pixels.

\addImage{images/IS_res.png}{Final Binary Image}{IS_res}{.25}

Through trial and error we found that the threshold method and the K-means method each produced varied results based on image composition. Essentially, depending on the image composition one would outperform the other. Combining these two gave us an fairly accurate binary image based on color. We used this image to resharpen the detail that was lost in the edge classified image due to dilation.

Once we have a binary image we can begin to actual segment the image into individual symbol tiles. Given our limited symbol set, the majority of this can be done through connected components analysis. If a set of pixels are all connected we simply classify this as a symbol and then extract the bounding box of that region. The only symbol this does not work for is the equals sign because it is a symbol made up of two disjoint regions. In order to handle this, we also combine symbols based on the distance of their centroids.

Finally, once we have these individual tiles we size them to 50x50 to provide a standard measure for feature extraction.  

